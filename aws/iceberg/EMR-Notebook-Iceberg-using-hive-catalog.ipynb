{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceberg Example Using Hive Catalog Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics covered in this example\n",
    "\n",
    "1) [Configuring Iceberg](#configure_iceberg) <br>\n",
    "2) [Creating an Iceberg Table](#create_table) <br>\n",
    "3) [DML Statements](#dml) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;a) [Inserts](#inserts) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;b) [Deletes](#deletes) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;d) [Updates](#updates) <br>\n",
    "4) [Schema Evolution](#schema_evolution) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;a) [Adding Columns](#adding_columns) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;c) [Dropping Columns](#dropping_columns) <br>\n",
    "5) [Time Travel](#time_travel) <br>\n",
    "&emsp;&emsp;&emsp;&emsp;a) [Rollback](#rollback) <br>\n",
    "6) [Partition Evolution](#partition_evolution) <br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Apache Iceberg (https://iceberg.apache.org/) is an open table format for huge analytic datasets. Iceberg adds tables to compute engines including Spark, Trino, PrestoDB, Flink and Hive using a high-performance table format that works just like a SQL table. Iceberg tracks individual data files in a table instead of directories. This allows writers to create data files in-place and only adds files to the table in an explicit commit. Every time a new file is inserted to any partition in this table, a new point-in-time snapshot of all the files get created. At the query time, there is no need to list a directory to find the files we need to work with, as the snapshot already has that information pre-populated during the write time (commonly known as snapshot isolation (https://en.wikipedia.org/wiki/Snapshot_isolation) in databases).\n",
    "\n",
    "Iceberg supports write, delete, update, and time travel operations with complete support for ACID transactions (https://en.wikipedia.org/wiki/ACID). Table changes are atomic and readers never see partial or uncommitted changes (serializable isolation (https://en.wikipedia.org/wiki/Isolation_(database_systems)#Serializable))\n",
    "\n",
    "Iceberg table format is an open specification at multiple levels. At the catalog level, you can plugin multiple types of catalogs such as hive, hadoop, AWS Glue Data Catalog etc. All these can co-exist. You can join tables across different types of catalogs. In this example, we are going to work with Hive Data Catalog\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Create an S3 bucket location to save sample dataset. In this example we use the path format: s3://<span style=\"color:red\">MYBUCKET</span>/iceberg/<span style=\"color:red\">YOUR-CATALOG-NAME</span>/tables/ \n",
    "    \n",
    "    For example: s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg\n",
    "\n",
    "update the MYBUCKET with the bucket which you create.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"configure_iceberg\"></a>\n",
    "## Configuring Iceberg on Spark session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't remember your bucket name, Run the ClI command below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your Spark session using the %%configure magic command. We will be using Hive Catalog for Iceberg Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Update the <span style=\"color:red\">MYBUCKET</span> in configuration below with you S3 bucket name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"conf\":{\n",
    "    \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.catalog.spark_catalog\":\"org.apache.iceberg.spark.SparkSessionCatalog\",\n",
    "    \"spark.sql.catalog.spark_catalog.type\":\"hive\",\n",
    "    \"spark.sql.catalog.dev\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.dev.type\":\"hadoop\",\n",
    "    \"spark.sql.catalog.dev.warehouse\":\"s3://MYBUCKET/iceberg/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_table\"></a>\n",
    "## Creating an Iceberg Table\n",
    "\n",
    "Create Iceberg Table, this table is using Hive Catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" DROP TABLE if exists dev.db.amazon_reviews_iceberg\"\"\")\n",
    "\n",
    "spark.sql(\"\"\" CREATE TABLE dev.db.amazon_reviews_iceberg \n",
    "(marketplace\tstring\n",
    ",customer_id\tstring\n",
    ",review_id\tstring\n",
    ",product_category\tstring\n",
    ",product_id\tstring\n",
    ",product_parent\tstring\n",
    ",product_title\tstring\n",
    ",star_rating\tint\n",
    ",helpful_votes\tint\n",
    ",total_votes\tint\n",
    ",vine\tstring\n",
    ",verified_purchase\tstring\n",
    ",review_headline\tstring\n",
    ",review_body\tstring\n",
    ",review_date\tbigint)\n",
    "\n",
    "USING iceberg \n",
    "location 's3://MYBUCKET/iceberg/db/amazon_reviews_iceberg'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dml\"></a>\n",
    "## DML Operations\n",
    "Icerberg supports all DML statements to add or modify data in your data lake: Inserts to add new data, Updates to modify specific columns in specific rows in your existing data, Deletes for GDPR and CCPA compliance and Upserts when you have incoming data that may have a mix of inserts and updates. Let us look at each of them now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inserts\"></a>\n",
    "### Inserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will be using simulated Amazon Product Reviews  dataset.**\n",
    "\n",
    "We are loading just one partition for sake of simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\n",
    "    \"s3://MYBUCKET/productreviews/simulatedproductreviews.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below cell to write data into the Iceberg table, We are writing just one partition for sake of simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sortWithinPartitions(\"review_date\").writeTo(\n",
    "    \"dev.db.amazon_reviews_iceberg\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify data is loaded into iceberg table successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from dev.db.amazon_reviews_iceberg limit 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deletes\"></a>\n",
    "### Deletes\n",
    "GDPR and CCPA regulations mandate timely removal of individual customer data and other records from datasets. Iceberg is designed to be able to handle these trivially.\n",
    "Now let us delete a record from our Iceberg table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all records from the table for verified_purchase = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"delete from dev.db.amazon_reviews_iceberg\n",
    "where verified_purchase = 'N'\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if data is deleted. Below query should produce zero records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"select * from dev.db.amazon_reviews_iceberg where verified_purchase = 'N'limit 9\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"updates\"></a>\n",
    "### Updates\n",
    "What if we want to go back and update an existing record? Let's change the `marketplace` from US to USA. Iceberg allows updates using a simple `UPDATE` and`SET` clause added to your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"UPDATE dev.db.amazon_reviews_iceberg\n",
    "SET marketplace = 'USA'\n",
    "WHERE marketplace = 'US'\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify 'marketplace' column is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from dev.db.amazon_reviews_iceberg limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"schema_evolution\"></a>\n",
    "## Schema Evolution\n",
    "Borrowing from the way columns work in databases, Iceberg tracks columns by using unique IDs and not by the column name. As long as the ID is the same, all the data still remains. You can safely add, drop, rename, update, or even reorder columns. You don’t have to rewrite the data for this. Schema evolution gets first class citizen treatment in Iceberg. Your ingest and read queries now have the freedom to be evolved without having to hide the schema inside JSON blobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will add a column to the iceberg table which we just created. We will add comment column to the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adding_columns\"></a>\n",
    "### Adding Columns\n",
    "Now we are going to add another column called `high_rated_product`. Iceberg also allows documenting the purpose for each column as `comment`, which helps a lot in a collaborative environment and quick lookup of data from business users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"ALTER TABLE dev.db.amazon_reviews_iceberg ADD COLUMNS (high_rated_product string comment 'Highly rated comment')\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add **High rated** flag to the comment column where rating is greater or equal to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"UPDATE dev.db.amazon_reviews_iceberg SET high_rated_product = 'High rated' where star_rating >=4\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify column is added successfully by quering the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "Select customer_id,review_id,product_id, product_title, star_rating, high_rated_product from dev.db.amazon_reviews_iceberg limit 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dropping_columns\"></a>\n",
    "### Dropping Columns\n",
    "Now, there is a change in business requirements, we are not interested in the `high_rated_product` column anymore and need to remove that column from our table. Iceberg allows us to do that easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"ALTER TABLE dev.db.amazon_reviews_iceberg DROP COLUMN high_rated_product\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"time_travel\"></a>\n",
    "## Time Travel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iceberg does give us a way to look at the history of changes to our table using the `history` metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM dev.db.amazon_reviews_iceberg.history\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also Iceberg does give us a way to look at the snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM dev.db.amazon_reviews_iceberg.snapshots\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rollback\"></a>\n",
    "### Rollback\n",
    "To undo the recent changes, we can execute Iceberg stored procedures using `CALL` statement to rollback the state of the table to any historical commit using `rollback_to_snapshot` stored procedure. We could also use `rollback_to_timestamp`.\n",
    "\n",
    "Recover the table to its original state, replace the <span style=\"color:red\">xxxxxxxxxxxxx</span> with Snapshot id from Table History. Use the snapshot_id with parent_id = null from Table History (first record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"CALL dev.system.rollback_to_snapshot('db.amazon_reviews_iceberg', xxxxxxxxxxxxx)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our table is now back to original state. You can verifiy this by observing verified_purchase column it shoould show both 'Y' and 'N' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from dev.db.amazon_reviews_iceberg limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"partition_evolution\"></a>\n",
    "##  Partition Evolution\n",
    "Let us look at the partitions we have in our table by querying the partitions metadata table. Iceberg keeps track of how many records (record_count column) and how many files (file_count column) are present in each partition. This is a very handy tool that could be used for performance and data quality related troubleshooting and diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from dev.db.amazon_reviews_iceberg.partitions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us list our s3 bucket location to see the partitions. Currently our table has no partitioning. All data files are just at the root data prefix. (Remember to replace <span style=\"color:red\">MYBUCKET</span> with your bucket name and if you use different prefixes, update the path as applicable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T00:46:24.009559Z",
     "iopub.status.busy": "2023-12-09T00:46:24.009331Z",
     "iopub.status.idle": "2023-12-09T00:46:24.077801Z",
     "shell.execute_reply": "2023-12-09T00:46:24.076930Z",
     "shell.execute_reply.started": "2023-12-09T00:46:24.009535Z"
    }
   },
   "source": [
    "<a id=\"Create new column in Date format\"></a>\n",
    "###  Create new column with Date datatype\n",
    "Let's create a new column **review_dt**.  \n",
    "We will use this new column for our new partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE dev.db.amazon_reviews_iceberg ADD COLUMNS (review_dt date);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the new column with date values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "UPDATE dev.db.amazon_reviews_iceberg set review_dt = date_add(to_date('1970-01-01'),cast(review_date as integer));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first create **yearly** partitions. Iceberg allows us to add partitions without having to perform any data movement or any additional changes to the underlying data. `ADD PARTITION FIELD` is a simple metadata operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE dev.db.amazon_reviews_iceberg add PARTITION FIELD years(review_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue to use the old partition on the old data. There is no change to the underlying partition structure on existing data as shown below (Again remember to replace <span style=\"color:red\">MYBUCKET</span> with your bucket name and if you use different prefixes, update the path as applicable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's insert new data for years 1998 and 2015. This will create duplicate rows, but we're just testing what happens if new data is inserted after new partition is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO dev.db.amazon_reviews_iceberg\n",
    "SELECT * FROM dev.db.amazon_reviews_iceberg WHERE year(review_dt)=1998 \n",
    "union \n",
    "SELECT * FROM dev.db.amazon_reviews_iceberg WHERE year(review_dt)=2015 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the S3 bucket structure again.  You should now see new directories based on the new partitions.  \n",
    "Before running the following cell, replace <span style=\"color:red\">MYBUCKET</span>  with your bucket name and if you use different prefixes, update the path as applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume down the time line, we realize we need to add **monthly** partitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE dev.db.amazon_reviews_iceberg ADD PARTITION FIELD months(review_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's insert new data after the month partition has been set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO dev.db.amazon_reviews_iceberg\n",
    "SELECT * FROM dev.db.amazon_reviews_iceberg WHERE year(review_dt)=1998 and month(review_dt)=9\n",
    "union \n",
    "SELECT * FROM dev.db.amazon_reviews_iceberg WHERE year(review_dt)=2000 and month(review_dt)=9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the results with new data with month partitions. Iceberg adds the new Monthly partitions under the year partitions under which we inserted our new records.   (Replace <span style=\"color:red\">MYBUCKET</span> with your bucket name and if you use different prefixes, update the path as applicable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "echo \"Top level ------------------------------------------------------------------------------------\"\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/\n",
    "echo \"\"\n",
    "echo \"inside of review_dt_year=1998 directory-------------------------------------------------------\"\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/review_dt_year=1998/\n",
    "echo \"\"\n",
    "echo \"inside of review_dt_year=2000 directory-------------------------------------------------------\"\n",
    "aws s3 ls s3://MYBUCKET/iceberg/db/amazon_reviews_iceberg/data/review_dt_year=2000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us query our table using the new monthly partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT marketplace, product_title, review_dt FROM dev.db.amazon_reviews_iceberg WHERE year(review_dt)=1998 and month(review_dt)=9 limit 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue to query our old data with using the year() transform. There is only the original review_dt column in the table. We don't have to store additional columns to accommodate multiple paritioning schemes. Everything is in the metadata giving us immense flexibility and making our data lake forward looking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "    select marketplace, customer_id, product_category, product_title, star_rating, verified_purchase, review_headline, review_dt\n",
    "    from dev.db.amazon_reviews_iceberg where year(review_dt) = 1999 limit 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THANK YOU! ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
